{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "ROOT_DIR = Path(\"vocab\")\n",
    "ROOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "COMMON_VOCAB_DIR = ROOT_DIR / \"common_english_words\"\n",
    "COMMON_VOCAB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_LIST = [\n",
    "    \"01-ai/Yi-34B-Chat\",\n",
    "    \"mistralai/Mistral-7B-v0.1\",\n",
    "    \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    \"meta-llama/Llama-2-13b-chat-hf\",\n",
    "    \"meta-llama/Llama-2-70b-chat-hf\",\n",
    "    \"codellama/CodeLlama-34b-Instruct-hf\",\n",
    "    \"lmsys/vicuna-13b-v1.5\",\n",
    "    \"Nexusflow/Starling-LM-7B-beta\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab file vocab/Yi-34B-Chat.json already exists. Skipping...\n",
      "Vocab file vocab/Mistral-7B-v0.1.json already exists. Skipping...\n",
      "Vocab file vocab/Mixtral-8x7B-Instruct-v0.1.json already exists. Skipping...\n",
      "Vocab file vocab/Llama-2-7b-chat-hf.json already exists. Skipping...\n",
      "Vocab file vocab/Llama-2-13b-chat-hf.json already exists. Skipping...\n",
      "Vocab file vocab/Llama-2-70b-chat-hf.json already exists. Skipping...\n",
      "Vocab file vocab/CodeLlama-34b-Instruct-hf.json already exists. Skipping...\n",
      "Vocab file vocab/vicuna-13b-v1.5.json already exists. Skipping...\n",
      "Vocab file vocab/Starling-LM-7B-beta.json already exists. Skipping...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Ensure ROOT_DIR exists at the start\n",
    "ROOT_DIR = Path(\"vocab\")\n",
    "ROOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_LIST = [\n",
    "    \"01-ai/Yi-34B-Chat\",\n",
    "    \"mistralai/Mistral-7B-v0.1\",\n",
    "    \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    \"meta-llama/Llama-2-13b-chat-hf\",\n",
    "    \"meta-llama/Llama-2-70b-chat-hf\",\n",
    "    \"codellama/CodeLlama-34b-Instruct-hf\",\n",
    "    \"lmsys/vicuna-13b-v1.5\",\n",
    "    \"Nexusflow/Starling-LM-7B-beta\",\n",
    "]\n",
    "\n",
    "\n",
    "def generate_save_path(model_path: str, root_dir: Path) -> Path:\n",
    "    \"\"\"Generates the save path for a model's vocabulary based on the model path.\"\"\"\n",
    "    _, model_name = model_path.split(\"/\")\n",
    "    return root_dir / f\"{model_name}.json\"\n",
    "\n",
    "\n",
    "def save_vocab(model_path: str, save_path: Path) -> None:\n",
    "    \"\"\"Saves the vocabulary of a given model if it doesn't already exist.\"\"\"\n",
    "    if save_path.exists():\n",
    "        print(f\"Vocab file {save_path} already exists. Skipping...\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        vocab = tokenizer.get_vocab()\n",
    "        save_path.write_text(json.dumps(vocab, ensure_ascii=False, indent=4))\n",
    "        print(f\"Successfully saved vocab for '{model_path}' to {save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save vocab for '{model_path}': {e}\")\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    for model_path in MODEL_LIST:\n",
    "        save_path = generate_save_path(model_path, ROOT_DIR)\n",
    "        save_vocab(model_path, save_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class Vocab(OrderedDict):\n",
    "    def __init__(self, model_vocab_paths: dict[str, Path], common_vocab_dir: Path):\n",
    "        super().__init__()\n",
    "        self.load_vocabs(model_vocab_paths, common_vocab_dir)\n",
    "\n",
    "    def load_vocabs(\n",
    "        self, model_vocab_paths: dict[str, Path], common_vocab_dir: Path\n",
    "    ) -> None:\n",
    "        # Load model-specific vocabularies\n",
    "        self.update(\n",
    "            {\n",
    "                model_name: self.load_vocab(path, is_json=True)\n",
    "                for model_name, path in model_vocab_paths.items()\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Dynamically load all common vocabularies from the specified directory\n",
    "        common_vocab_paths = common_vocab_dir.glob(\"*.txt\")\n",
    "        self.update({path.stem: self.load_vocab(path) for path in common_vocab_paths})\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vocab(path: Path, is_json: bool = False) -> set[str]:\n",
    "        with path.open(\"r\", encoding=\"utf-8\") as file:\n",
    "            if is_json:\n",
    "                return set(json.load(file))\n",
    "            return {line.strip() for line in file if line.strip()}\n",
    "\n",
    "\n",
    "def create_model_vocab_paths(model_list: list[str], root_dir: Path) -> dict[str, Path]:\n",
    "    return {\n",
    "        Path(model).parts[-1]: root_dir / f\"{Path(model).parts[-1]}.json\"\n",
    "        for model in model_list\n",
    "    }\n",
    "\n",
    "\n",
    "model_vocab_paths = create_model_vocab_paths(MODEL_LIST, ROOT_DIR)\n",
    "vocab = Vocab(model_vocab_paths, COMMON_VOCAB_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['Yi-34B-Chat', 'Mistral-7B-v0.1', 'Mixtral-8x7B-Instruct-v0.1', 'Llama-2-7b-chat-hf', 'Llama-2-13b-chat-hf', 'Llama-2-70b-chat-hf', 'CodeLlama-34b-Instruct-hf', 'vicuna-13b-v1.5', 'Starling-LM-7B-beta', 'wiki_most_100_common_word_in_english', 'oxford_3000', 'oxford_5000'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
